{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop({'RowNumber','CustomerId','Surname'},axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
       "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
       "       'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unique(df):\n",
    "    for i in df:\n",
    "        print(f'{i} : {df[i].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "Unique(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Geography'].replace({'France': 0 , 'Spain' : 1 , 'Germany' : 2},inplace=True)\n",
    "df['Gender'].replace({'Female' : 0 , 'Male' : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : [0 1 2]\n",
      "Gender : [0 1]\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "Unique(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
       "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
       "       'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsc= ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Scaler = MinMaxScaler()\n",
    "df[mmsc] = Scaler.fit_transform(df[mmsc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
      " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
      " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
      " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
      " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
      " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
      " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
      " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
      " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
      " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
      " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
      " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
      " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
      " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
      " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
      " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
      " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
      " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
      " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
      " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
      " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
      " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
      " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
      " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
      " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
      " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
      " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
      " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
      " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
      " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
      " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
      " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
      " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
      " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
      " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
      " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
      " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
      " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
      " 0.124 0.064 0.046 0.138]\n",
      "Geography : [0 1 2]\n",
      "Gender : [0 1]\n",
      "Age : [0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
      " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
      " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
      " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
      " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
      " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
      " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
      " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
      " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
      " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
      " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
      " 0.81081081 0.85135135 1.         0.87837838]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "Unique(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        float64\n",
       "Geography            int64\n",
       "Gender               int64\n",
       "Age                float64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "z = df.drop('Exited',axis='columns')\n",
    "y = df['Exited']\n",
    "print(z.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ztrain,ztest,ytrain,ytest=train_test_split(z,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "(2000, 10)\n",
      "(8000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(ztrain.shape)\n",
    "print(ztest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.5359 - accuracy: 0.7546\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4770 - accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4636 - accuracy: 0.8004\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4546 - accuracy: 0.8016\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.4461 - accuracy: 0.8026\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4375 - accuracy: 0.8070\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4290 - accuracy: 0.8104\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4202 - accuracy: 0.8176\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4106 - accuracy: 0.8231\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.4025 - accuracy: 0.8270\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3958 - accuracy: 0.8311\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3897 - accuracy: 0.8334\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3844 - accuracy: 0.8359\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3805 - accuracy: 0.8370\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3772 - accuracy: 0.8405\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3757 - accuracy: 0.8382\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3724 - accuracy: 0.8404\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3708 - accuracy: 0.8407\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3694 - accuracy: 0.8431\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3680 - accuracy: 0.8428\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3663 - accuracy: 0.8456\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3649 - accuracy: 0.8445\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3638 - accuracy: 0.8474\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3644 - accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3620 - accuracy: 0.8464\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3615 - accuracy: 0.8466\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3602 - accuracy: 0.8474\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3608 - accuracy: 0.8453\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3599 - accuracy: 0.8478\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3586 - accuracy: 0.8490\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3584 - accuracy: 0.8471\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3578 - accuracy: 0.8506\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3562 - accuracy: 0.8496\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3564 - accuracy: 0.8510\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3555 - accuracy: 0.8520\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3546 - accuracy: 0.8514\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3548 - accuracy: 0.8531\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3546 - accuracy: 0.8531\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3525 - accuracy: 0.8536\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3518 - accuracy: 0.8541\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3509 - accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3512 - accuracy: 0.8559\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3504 - accuracy: 0.8553\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3492 - accuracy: 0.8568\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3485 - accuracy: 0.8561\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3496 - accuracy: 0.8550\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3480 - accuracy: 0.8575\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3492 - accuracy: 0.8566\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3471 - accuracy: 0.8568\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3485 - accuracy: 0.8564\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3471 - accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3466 - accuracy: 0.8583\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3462 - accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3464 - accuracy: 0.8586\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3454 - accuracy: 0.8576\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3464 - accuracy: 0.8572\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3444 - accuracy: 0.8587\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3448 - accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3442 - accuracy: 0.8583\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3452 - accuracy: 0.8606\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3442 - accuracy: 0.8580\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3440 - accuracy: 0.8601\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3439 - accuracy: 0.8605\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3435 - accuracy: 0.8602\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3429 - accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3429 - accuracy: 0.8589\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3429 - accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3418 - accuracy: 0.8622\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3418 - accuracy: 0.8610\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3419 - accuracy: 0.8597\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3422 - accuracy: 0.8595\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3417 - accuracy: 0.8597\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3424 - accuracy: 0.8612\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3419 - accuracy: 0.8624\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3411 - accuracy: 0.8635\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3415 - accuracy: 0.8608\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3413 - accuracy: 0.8606\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3411 - accuracy: 0.8621\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3408 - accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3404 - accuracy: 0.8619\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3399 - accuracy: 0.8604\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3401 - accuracy: 0.8626\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3398 - accuracy: 0.8606\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3406 - accuracy: 0.8597\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3395 - accuracy: 0.8600\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3389 - accuracy: 0.8626\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3401 - accuracy: 0.8619\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3398 - accuracy: 0.8616\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3380 - accuracy: 0.8610\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3391 - accuracy: 0.8605\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3383 - accuracy: 0.8624\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3389 - accuracy: 0.8633\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3394 - accuracy: 0.8601\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3385 - accuracy: 0.8615\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3384 - accuracy: 0.8610\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3381 - accuracy: 0.8622\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3383 - accuracy: 0.8634\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3376 - accuracy: 0.8635\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3395 - accuracy: 0.8618\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3377 - accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1494a6d3e88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(10, ), activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(ztrain, ytrain, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.3558 - accuracy: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35575968527793883, 0.852]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ztest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "yp=model.predict(ztest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01431862],\n",
       "       [0.6253409 ],\n",
       "       [0.35174513],\n",
       "       [0.14132875],\n",
       "       [0.03673863],\n",
       "       [0.16243571],\n",
       "       [0.14047617],\n",
       "       [0.7508025 ],\n",
       "       [0.24578628],\n",
       "       [0.25425225]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = []\n",
    "for i in yp:\n",
    "    if i > 0.5:\n",
    "        ypred.append(1)\n",
    "    else:\n",
    "        ypred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1576\n",
      "           1       0.72      0.49      0.59       424\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.80      0.72      0.75      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=ytest,predictions=ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
